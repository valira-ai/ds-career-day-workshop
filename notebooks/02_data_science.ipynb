{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science\n",
    "In this part we will go over example tasks a data scientist would perform.\n",
    "Those include:\n",
    "- **Exploratory data analysis**: This is the process of investigating and summarizing data sets in order to gain insights and formulate hypotheses. It involves visualizing and summarizing data using various statistical and graphical techniques in order to understand patterns, trends, and relationships in the data,\n",
    "- **Feature engineering**: This refers to the process of transforming raw data into features that can be used as inputs to machine learning algorithms. It involves selecting, extracting, and transforming relevant features from the data to improve the performance of the models,\n",
    "- **Feature selection**: This is the process of selecting a subset of relevant features from a larger set of features in order to improve the performance of the models. It involves using various techniques such as correlation analysis, mutual information, and regularization to identify the most important features,\n",
    "- **Splitting data**: This is the process of dividing a data set into two or more subsets, typically a training set and a testing set. The training set is used to train the machine learning models, while the testing set is used to evaluate their performance,\n",
    "- **Model selection**: This is the process of selecting the most appropriate machine learning model for a particular problem. It involves evaluating various models based on their performance on a given data set and selecting the one that performs the best,\n",
    "- **Model validation**: This is the process of evaluating the performance of machine learning models using validation techniques such as cross-validation and holdout validation. It involves assessing the accuracy, precision, recall, and other metrics of the models on a separate test set in order to avoid overfitting and ensure generalization,\n",
    "- **Metrics**: These are measures used to evaluate the performance of machine learning models. They include accuracy, precision, recall, F1 score, ROC AUC, and many others,\n",
    "- **Report**: This is a document that summarizes the findings and results of a data science project. It typically includes a description of the problem, the data used, the methods and techniques used, the results obtained, and the conclusions drawn. The report should be clear, concise, and well-organized, and it should communicate the findings to a non-technical audience."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Importing libraries and getting the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "\n",
    "import psycopg\n",
    "import folium\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from plotnine import *\n",
    "from geopy.distance import great_circle as GRC\n",
    "from sklearn.model_selection import train_test_split, RepeatedKFold\n",
    "from sklearn.metrics import mean_squared_error, root_mean_squared_error\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg.connect(\n",
    "   dbname=os.environ.get(\"DB_NAME\"),\n",
    "   user=os.environ.get(\"DB_USER\"),\n",
    "   password=os.environ.get(\"DB_PASSWORD\"),\n",
    "   host=os.environ.get(\"DB_HOST\"),\n",
    "   port= os.environ.get(\"DB_PORT\")\n",
    ")\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_sql('SELECT * FROM vw_airbnb', con=conn)\n",
    "conn.close ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All rows having at least one -1 in numeric columns\n",
    "numeric_cols = data.select_dtypes(include=[np.number]).columns\n",
    "neg1_mask = (data[numeric_cols] == -1)\n",
    "\n",
    "rows_with_neg1 = data[neg1_mask.any(axis=1)]\n",
    "rows_with_neg1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.replace(-1, np.nan)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_dict = [{col: data[col].isnull().sum()/data[col].shape[0]} for col in data.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check individual variables\n",
    "Make sure they make sense given what you know about the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[0].center_latitude, data.iloc[0].center_longitude"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*longitude* & *latitude*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking longitude and latitude values (are they all in Paris?).\n",
    "center = [data.iloc[0].center_latitude, data.iloc[0].center_longitude]\n",
    "\n",
    "# creating map\n",
    "map = folium.Map(location = center, zoom_start = 12)\n",
    "random_rows = random.sample(list(data.iterrows()), k=1000)\n",
    "\n",
    "min_max_idx = [data['latitude'].idxmin(), data['longitude'].idxmin(), data['latitude'].idxmax(), data['longitude'].idxmax()]\n",
    "random_rows.extend(list(data.iloc[min_max_idx].iterrows()))\n",
    "\n",
    "for i, j in random_rows:\n",
    "    location = [j['latitude'], j['longitude']]\n",
    "    folium.Marker(location, popup = f'Price: {j[\"price\"]}').add_to(map)\n",
    "    if i == 999:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "map"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*price*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem with price... Its a string\n",
    "data[\"price\"] = data[\"price\"].apply(lambda x: float(x.replace(\"$\", \"\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"price\"].nlargest(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"price\"].nsmallest(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values were encoded as -1 in the dataset so we remove the rows\n",
    "data = data.replace(-1, np.nan)\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the price histogram\n",
    "(\n",
    "    ggplot(data, aes(x=\"price\"))\n",
    "    + geom_histogram()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['price'].value_counts().iloc[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    ggplot(data, aes(x=\"price\"))\n",
    "    + geom_histogram(binwidth=15, fill=\"steelblue\", color=\"white\")\n",
    "    + labs(title=\"Listing price distribution\", x=\"Price (USD)\", y=\"Count\")\n",
    "    + theme_minimal()\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*minimum_nights*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"minimum_nights\"].nlargest(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"minimum_nights\"].nsmallest(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['minimum_nights'].value_counts().iloc[:30]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*city_name*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"city_name\"].nunique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*room_type_name*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"room_type_name\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"room_type_name\"].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*neighbourhood_name*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"neighbourhood_name\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"neighbourhood_name\"].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Amenities*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "am = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, amenities in data.amenities.items():\n",
    "    amenities_split = amenities.split(\",\")\n",
    "    for amenity in amenities_split:\n",
    "        am.add(amenity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "am"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Features*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, features in data.features.items():\n",
    "    features_split = features.split(\",\")\n",
    "    for feature in features_split:\n",
    "        fe.add(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "fe"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Cancelation Policy*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"cancel_policy_name\"].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*bed_type_name*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"bed_type_name\"].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*property_type_name*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"property_type_name\"].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"longitude_to_center\"] = data[[\"longitude\", \"center_longitude\"]].apply(lambda x: x[\"longitude\"] - x[\"center_longitude\"], axis=1)\n",
    "data[\"latitude_to_center\"] = data[[\"latitude\", \"center_latitude\"]].apply(lambda x: x[\"latitude\"] - x[\"center_latitude\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"distance_to_center\"] = data[[\"longitude\", \n",
    "                                    \"latitude\", \n",
    "                                    \"center_longitude\", \n",
    "                                    \"center_latitude\"]].apply(lambda x: GRC((x[\"latitude\"], x[\"longitude\"]), \n",
    "                                                                            (x[\"center_latitude\"], x[\"center_longitude\"])).km, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbourhood_dummies = pd.get_dummies(data[\"neighbourhood_name\"], drop_first=True)\n",
    "room_type_dummies = pd.get_dummies(data[\"room_type_name\"], drop_first=True)\n",
    "bed_type_dummies = pd.get_dummies(data[\"bed_type_name\"])\n",
    "property_type_dummies = pd.get_dummies(data[\"property_type_name\"])\n",
    "cancellation_policy_dummies = pd.get_dummies(data[\"cancel_policy_name\"], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancellation_policy_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancellation_policy_dummies[\"strict\"] = (cancellation_policy_dummies[\"strict\"] | \n",
    "                                        cancellation_policy_dummies[\"super_strict_30\"] |  \n",
    "                                        cancellation_policy_dummies[\"super_strict_60\"])\n",
    "cancellation_policy_dummies = cancellation_policy_dummies.drop(columns=[\"super_strict_60\", \"super_strict_30\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bed_type_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bed_type_dummies = bed_type_dummies.drop(columns=[\"Couch\", \"Futon\", \"Airbed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "property_type_dummies = property_type_dummies.drop(columns=[\"Boutique hotel\", \"Townhouse\", \"Guesthouse\", \"Dorm\",                     \n",
    "                                                            \"Hostel\", \"Boat\", \"Serviced apartment\", \"Cabin\", \"Villa\",                    \n",
    "                                                            \"Timeshare\", \"Earth House\", \"Camper/RV\", \"Cave\", \"Other\",\n",
    "                                                            \"Bungalow\", \"Igloo\", \"Treehouse\", \"Tipi\", \"Chalet\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.join(neighbourhood_dummies)\n",
    "data = data.join(room_type_dummies)\n",
    "data = data.join(bed_type_dummies)\n",
    "data = data.join(property_type_dummies)\n",
    "data = data.join(cancellation_policy_dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.drop([\"neighbourhood_name\", \"longitude\", \"latitude\", 'listing_given_id',\n",
    "                \"property_type_name\", \"center_longitude\", \"center_latitude\", \n",
    "                \"price\", \"minimum_nights\", \"room_type_name\", \"bed_type_name\",\n",
    "                \"cancel_policy_name\", \"features\", \"amenities\", \"city_name\"], axis=1)\n",
    "target = data[\"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df, target, test_size=0.20, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = [\"accommodates\", \"bathrooms\",\t\"bedrooms\",\t\n",
    "                    \"beds\", \"longitude_to_center\",\n",
    "                    \"latitude_to_center\",\t\"distance_to_center\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = [\"longitude_to_center\", \n",
    "                    \"latitude_to_center\",\t\"distance_to_center\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X_train[numeric_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = scaler.transform(X_train[numeric_columns])\n",
    "X_test_scaled = scaler.transform(X_test[numeric_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(columns=numeric_columns)\n",
    "X_test = X_test.drop(columns=numeric_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "\n",
    "X_train = pd.concat([X_train, pd.DataFrame(X_train_scaled, columns=numeric_columns)], axis=1)\n",
    "X_test = pd.concat([X_test, pd.DataFrame(X_test_scaled, columns=numeric_columns)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPRegressor(random_state=42, early_stopping=True, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_mean_squared_error(y_test, preds) # Relative mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = model.feature_importances_ # Only for XGBoost model\n",
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = X_train.columns\n",
    "\n",
    "fi = (pd.DataFrame({'feature': features, 'importance': importances})\n",
    "        .sort_values('importance', ascending=False))\n",
    "\n",
    "fi.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    ggplot(fi, aes(x='reorder(feature, importance)', y='importance'))\n",
    "    + geom_col(fill='steelblue')\n",
    "    + coord_flip()\n",
    "    + labs(title='XGBoost Feature Importances', x='Feature', y='Importance')\n",
    "    + theme_minimal()\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
